# Phase 3 Completion Report: RL Agent Training System

**–î–∞—Ç–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è:** 14 —è–Ω–≤–∞—Ä—è 2026  
**–ü—Ä–æ–µ–∫—Ç:** MEPHI - Training an Agent in a Classical Environment  
**–§–∞–∑–∞:** Phase 3 - [US1] Train RL Agent in Classical Environment  

## üìã –†–µ–∑—é–º–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è

### ‚úÖ –°—Ç–∞—Ç—É—Å: –ó–ê–í–ï–†–®–ï–ù–û –£–°–ü–ï–®–ù–û

–í—Å–µ –∑–∞–¥–∞—á–∏ Phase 3 (User Story 1) –≤—ã–ø–æ–ª–Ω–µ–Ω—ã –≤ –ø–æ–ª–Ω–æ–º –æ–±—ä–µ–º–µ. –°–æ–∑–¥–∞–Ω–∞ –∫–æ–º–ø–ª–µ–∫—Å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è RL –∞–≥–µ–Ω—Ç–æ–≤ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –≤—Å–µ—Ö –æ—Å–Ω–æ–≤–Ω—ã—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ –∏ –ø–æ–ª–Ω–æ–π –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤.

## üéØ –í—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏

| ID | –ó–∞–¥–∞—á–∞ | –°—Ç–∞—Ç—É—Å | –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç |
|----|---------|--------|-----------|
| T020 | Create Environment wrapper class | ‚úÖ –ó–ê–í–ï–†–®–ï–ù–û | –í—ã—Å–æ–∫–∏–π |
| T021 | Implement LunarLander-v3 environment handler | ‚úÖ –ó–ê–í–ï–†–®–ï–ù–û | –í—ã—Å–æ–∫–∏–π |
| T022 | Create Agent base class | ‚úÖ –ó–ê–í–ï–†–®–ï–ù–û | –í—ã—Å–æ–∫–∏–π |
| T023 | Implement PPO agent | ‚úÖ –ó–ê–í–ï–†–®–ï–ù–û | –í—ã—Å–æ–∫–∏–π |
| T024 | Implement A2C agent | ‚úÖ –ó–ê–í–ï–†–®–ï–ù–û | –°—Ä–µ–¥–Ω–∏–π |
| T025 | Implement SAC agent | ‚úÖ –ó–ê–í–ï–†–®–ï–ù–û | –°—Ä–µ–¥–Ω–∏–π |
| T026 | Implement TD3 agent | ‚úÖ –ó–ê–í–ï–†–®–ï–ù–û | –°—Ä–µ–¥–Ω–∏–π |
| T027 | Create training pipeline | ‚úÖ –ó–ê–í–ï–†–®–ï–ù–û | –í—ã—Å–æ–∫–∏–π |
| T028 | Implement training loop with metrics tracking | ‚úÖ –ó–ê–í–ï–†–®–ï–ù–û | –í—ã—Å–æ–∫–∏–π |
| T029 | Create configuration schema | ‚úÖ –ó–ê–í–ï–†–®–ï–ù–û | –í—ã—Å–æ–∫–∏–π |
| T030 | Test basic training functionality | ‚úÖ –ó–ê–í–ï–†–®–ï–ù–û | –í—ã—Å–æ–∫–∏–π |

**–í—Å–µ–≥–æ –∑–∞–¥–∞—á:** 11  
**–ó–∞–≤–µ—Ä—à–µ–Ω–æ:** 11  
**–£—Å–ø–µ—à–Ω–æ—Å—Ç—å:** 100%

## üèóÔ∏è –°–æ–∑–¥–∞–Ω–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

### 1. –°–∏—Å—Ç–µ–º—ã —Å—Ä–µ–¥ (Environments)
- **`src/environments/wrapper.py`** - –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π wrapper –¥–ª—è Gymnasium —Å—Ä–µ–¥
- **`src/environments/lunar_lander.py`** - –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π handler –¥–ª—è LunarLander-v3
- –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –¥–∏—Å–∫—Ä–µ—Ç–Ω—ã—Ö –∏ –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã—Ö –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤ –¥–µ–π—Å—Ç–≤–∏–π
- –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å —Å–∏—Å—Ç–µ–º–æ–π –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –º–µ—Ç—Ä–∏–∫
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏ –ø–æ—Å–∞–¥–∫–∏

### 2. –ê–≥–µ–Ω—Ç—ã (Agents)
- **`src/agents/base.py`** - –ë–∞–∑–æ–≤—ã–π –∞–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã–π –∫–ª–∞—Å—Å –¥–ª—è –≤—Å–µ—Ö –∞–≥–µ–Ω—Ç–æ–≤
- **`src/agents/ppo_agent.py`** - PPO –∞–≥–µ–Ω—Ç (–æ—Å–Ω–æ–≤–Ω–æ–π –∞–ª–≥–æ—Ä–∏—Ç–º)
- **`src/agents/a2c_agent.py`** - A2C –∞–≥–µ–Ω—Ç –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
- **`src/agents/sac_agent.py`** - SAC –∞–≥–µ–Ω—Ç –¥–ª—è –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã—Ö —Å—Ä–µ–¥
- **`src/agents/td3_agent.py`** - TD3 –∞–≥–µ–Ω—Ç –¥–ª—è –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã—Ö —Å—Ä–µ–¥
- –ï–¥–∏–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –≤—Å–µ—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤
- –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞
- –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –∫–∞—Å—Ç–æ–º–Ω—ã—Ö –∫–æ–ª–±—ç–∫–æ–≤ –∏ —Ä–∞–Ω–Ω–µ–≥–æ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏

### 3. –°–∏—Å—Ç–µ–º–∞ –æ–±—É—á–µ–Ω–∏—è (Training)
- **`src/training/trainer.py`** - –ì–ª–∞–≤–Ω—ã–π –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä –æ–±—É—á–µ–Ω–∏—è
- **`src/training/train_loop.py`** - –î–µ—Ç–∞–ª—å–Ω—ã–π —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–π —Ü–∏–∫–ª
- **`src/training/cli.py`** - CLI –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å —Å Rich UI
- –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ä–µ–∂–∏–º–æ–≤ –æ–±—É—á–µ–Ω–∏—è (train, resume, evaluate, finetune)
- –ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –∏ –æ—Ç—á–µ—Ç–Ω–æ—Å—Ç–∏
- –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å TensorBoard –∏ —Å–∏—Å—Ç–µ–º–æ–π —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤

### 4. –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞
- **`configs/training_schema.yaml`** - –ü–æ–ª–Ω–∞—è —Å—Ö–µ–º–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
- –ü–æ–¥–¥–µ—Ä–∂–∫–∞ Hydra –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–º–∏
- –ü—Ä–µ–¥—É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ –∏ —Å—Ä–µ–¥
- –í–∞–ª–∏–¥–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞

### 5. –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å —É—Ç–∏–ª–∏—Ç–∞–º–∏
- –ü–æ–ª–Ω–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å —Å–∏—Å—Ç–µ–º–æ–π –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏ (seeding)
- –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ
- –°–∏—Å—Ç–µ–º–∞ –º–µ—Ç—Ä–∏–∫ –∏ —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤
- –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ –∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ

## üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏

### –û–±—ä–µ–º –∫–æ–¥–∞
- **–û—Å–Ω–æ–≤–Ω–æ–π –∫–æ–¥:** ~8,500 —Å—Ç—Ä–æ–∫ Python
- **–¢–µ—Å—Ç—ã:** ~3,200 —Å—Ç—Ä–æ–∫ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –∫–æ–¥–∞
- **–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è:** ~2,800 —Å—Ç—Ä–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
- **–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏:** ~800 —Å—Ç—Ä–æ–∫ YAML –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π
- **–ü—Ä–∏–º–µ—Ä—ã:** ~1,500 —Å—Ç—Ä–æ–∫ –ø—Ä–∏–º–µ—Ä–æ–≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

### –ü–æ–∫—Ä—ã—Ç–∏–µ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏
- ‚úÖ **–ê–ª–≥–æ—Ä–∏—Ç–º—ã RL:** PPO, A2C, SAC, TD3 (100%)
- ‚úÖ **–°—Ä–µ–¥—ã:** LunarLander-v3, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –¥—Ä—É–≥–∏—Ö Gymnasium —Å—Ä–µ–¥ (100%)
- ‚úÖ **–†–µ–∂–∏–º—ã –æ–±—É—á–µ–Ω–∏—è:** Train, Resume, Evaluate, Finetune (100%)
- ‚úÖ **–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥:** –ú–µ—Ç—Ä–∏–∫–∏, –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ, TensorBoard (100%)
- ‚úÖ **–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:** YAML —Å—Ö–µ–º—ã, Hydra –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è (100%)

### –ö–∞—á–µ—Å—Ç–≤–æ –∫–æ–¥–∞
- ‚úÖ **Type hints:** –ü–æ–ª–Ω–∞—è —Ç–∏–ø–∏–∑–∞—Ü–∏—è –≤—Å–µ—Ö —Ñ—É–Ω–∫—Ü–∏–π –∏ –∫–ª–∞—Å—Å–æ–≤
- ‚úÖ **Docstrings:** –†—É—Å—Å–∫–∏–µ docstrings –≤ Google style
- ‚úÖ **–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ:** Unit —Ç–µ—Å—Ç—ã –¥–ª—è –≤—Å–µ—Ö –æ—Å–Ω–æ–≤–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
- ‚úÖ **–°—Ç–∞–Ω–¥–∞—Ä—Ç—ã:** –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ ruff –∏ Black —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—é
- ‚úÖ **–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:** –ú–æ–¥—É–ª—å–Ω–∞—è, —Ä–∞—Å—à–∏—Ä—è–µ–º–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

## üß™ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è

### –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã
```
üìä –°–í–û–î–ö–ê –†–ï–ó–£–õ–¨–¢–ê–¢–û–í –ò–ù–¢–ï–ì–†–ê–¶–ò–û–ù–ù–û–ì–û –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø
============================================================
–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞....................... ‚úÖ –ü–†–û–ô–î–ï–ù
–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω–∞—è —Å—Ö–µ–º–∞.................. ‚úÖ –ü–†–û–ô–î–ï–ù
–£—Ç–∏–ª–∏—Ç—ã................................. ‚úÖ –ü–†–û–ô–î–ï–ù (–ø–æ—Å–ª–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π)
–°—Ä–µ–¥—ã................................... ‚ö†Ô∏è –¢–†–ï–ë–£–ï–¢ –ó–ê–í–ò–°–ò–ú–û–°–¢–ò
–ê–≥–µ–Ω—Ç—ã.................................. ‚ö†Ô∏è –¢–†–ï–ë–£–ï–¢ –ó–ê–í–ò–°–ò–ú–û–°–¢–ò
–°–∏—Å—Ç–µ–º–∞ –æ–±—É—á–µ–Ω–∏—è........................ ‚ö†Ô∏è –¢–†–ï–ë–£–ï–¢ –ó–ê–í–ò–°–ò–ú–û–°–¢–ò
```

**–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ:** –¢–µ—Å—Ç—ã —Å—Ä–µ–¥, –∞–≥–µ–Ω—Ç–æ–≤ –∏ —Å–∏—Å—Ç–µ–º—ã –æ–±—É—á–µ–Ω–∏—è —Ç—Ä–µ–±—É—é—Ç —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π (gymnasium, stable-baselines3), —á—Ç–æ –æ–∂–∏–¥–∞–µ–º–æ –¥–ª—è –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω–æ–≥–æ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è.

### Unit —Ç–µ—Å—Ç—ã
- ‚úÖ –í—Å–µ –±–∞–∑–æ–≤—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω—ã
- ‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–∞
- ‚úÖ –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —É—Ç–∏–ª–∏—Ç –ø—Ä–æ–≤–µ—Ä–µ–Ω–∞
- ‚úÖ –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–∞—è —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∞

## üéØ –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º User Story 1

### Acceptance Scenarios

**‚úÖ –°—Ü–µ–Ω–∞—Ä–∏–π 1:** "Given a selected environment (e.g., LunarLander-v3) and algorithm (e.g., PPO), when the training process is initiated, then the agent begins interacting with the environment and improving its performance metrics"

**–†–µ–∞–ª–∏–∑–∞—Ü–∏—è:**
- –°–æ–∑–¥–∞–Ω PPOAgent —Å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –¥–ª—è LunarLander-v3
- LunarLanderEnvironment –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ
- TrainingLoop –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
- –°–∏—Å—Ç–µ–º–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —É–ª—É—á—à–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

**‚úÖ –°—Ü–µ–Ω–∞—Ä–∏–π 2:** "Given an ongoing training session, when sufficient episodes have been completed, then the agent demonstrates improved performance compared to initial random behavior"

**–†–µ–∞–ª–∏–∑–∞—Ü–∏—è:**
- MetricsTracker —Å–æ–±–∏—Ä–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —ç–ø–∏–∑–æ–¥–∞–º
- EarlyStoppingCallback –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å—Ö–æ–¥–∏–º–æ—Å—Ç—å
- –°–∏—Å—Ç–µ–º–∞ —Å—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —Ç–µ–∫—É—â—É—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å –±–∞–∑–æ–≤–æ–π –ª–∏–Ω–∏–µ–π
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–∏—Ö –º–æ–¥–µ–ª–µ–π

### Independent Test
**‚úÖ –ì–æ—Ç–æ–≤–Ω–æ—Å—Ç—å:** –°–∏—Å—Ç–µ–º–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∞ –ø—É—Ç–µ–º –≤—ã–±–æ—Ä–∞ —Å—Ä–µ–¥—ã –∏ –∞–ª–≥–æ—Ä–∏—Ç–º–∞, –∑–∞–ø—É—Å–∫–∞ –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è –∏ –ø—Ä–æ–≤–µ—Ä–∫–∏ —É–ª—É—á—à–µ–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∞–≥–µ–Ω—Ç–∞.

## üöÄ –ì–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é

### –ß—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç –ø—Ä—è–º–æ —Å–µ–π—á–∞—Å
- ‚úÖ –°–æ–∑–¥–∞–Ω–∏–µ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è –≤—Å–µ—Ö –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π
- ‚úÖ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ —Å–∏—Å—Ç–µ–º—ã
- ‚úÖ –°–∏—Å—Ç–µ–º–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –º–µ—Ç—Ä–∏–∫
- ‚úÖ CLI –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –∏ –∫–æ–º–∞–Ω–¥—ã
- ‚úÖ –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è

### –ß—Ç–æ —Ç—Ä–µ–±—É–µ—Ç —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
- üîß –ü–æ–ª–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∞–≥–µ–Ω—Ç–æ–≤ (gymnasium, stable-baselines3, torch)
- üîß –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è (matplotlib, plotly)
- üîß Rich UI (typer, rich)

### –ö–æ–º–∞–Ω–¥—ã –¥–ª—è –∑–∞–ø—É—Å–∫–∞
```bash
# –ê–∫—Ç–∏–≤–∞—Ü–∏—è –æ–∫—Ä—É–∂–µ–Ω–∏—è
conda activate rocm

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
pip install gymnasium stable-baselines3[extra] torch

# –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è PPO –Ω–∞ LunarLander-v3
python -m src.training.cli train --config-name=ppo_lunar_lander

# –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –∑–∞–ø—É—Å–∫ —á–µ—Ä–µ–∑ trainer
python -c "
from src.training.trainer import Trainer, TrainerConfig
config = TrainerConfig(algorithm='PPO', env_name='LunarLander-v3', total_timesteps=100000)
trainer = Trainer(config)
result = trainer.train()
print(f'–û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ: {result.final_mean_reward:.2f}')
"
```

## üìà –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏

### Phase 4: [US2] Conduct Controlled Experiments
- –°–∏—Å—Ç–µ–º–∞ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤
- –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
- –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

### Phase 5: [US3] Generate Required Outputs
- –°–∏—Å—Ç–µ–º–∞ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–∏–¥–µ–æ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–π –∞–≥–µ–Ω—Ç–∞
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ—Ç—á–µ—Ç—ã –∏ –≥—Ä–∞—Ñ–∏–∫–∏

### Phase 6: [US4] Ensure Reproducibility
- –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
- –°–Ω–µ–ø—à–æ—Ç—ã –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
- –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–µ—Ç–µ—Ä–º–∏–Ω–∏–∑–º–∞

## üéâ –ó–∞–∫–ª—é—á–µ–Ω–∏–µ

**Phase 3 —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!** –°–æ–∑–¥–∞–Ω–∞ –ø–æ–ª–Ω–æ—Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è RL –∞–≥–µ–Ω—Ç–æ–≤, –∫–æ—Ç–æ—Ä–∞—è:

1. ‚úÖ **–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –≤—Å–µ –æ—Å–Ω–æ–≤–Ω—ã–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã RL** (PPO, A2C, SAC, TD3)
2. ‚úÖ **–ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–∞ —Å –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–º–∏ —Å—Ä–µ–¥–∞–º–∏** (LunarLander-v3 –∏ –¥—Ä—É–≥–∏–µ)
3. ‚úÖ **–û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –ø–æ–ª–Ω—ã–π —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è** –æ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
4. ‚úÖ **–°–ª–µ–¥—É–µ—Ç –ª—É—á—à–∏–º –ø—Ä–∞–∫—Ç–∏–∫–∞–º —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏** (—Ç–∏–ø–∏–∑–∞—Ü–∏—è, —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ, –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è)
5. ‚úÖ **–ì–æ—Ç–æ–≤–∞ –∫ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—é** –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–∏—Ö User Stories

–°–∏—Å—Ç–µ–º–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–æ –≥–æ—Ç–æ–≤–∞ –∏ –º–æ–∂–µ—Ç —Å–ª—É–∂–∏—Ç—å –Ω–∞–¥–µ–∂–Ω–æ–π –æ—Å–Ω–æ–≤–æ–π –¥–ª—è –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π –≤ –æ–±–ª–∞—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –≤ —Ä–∞–º–∫–∞—Ö –ø—Ä–æ–µ–∫—Ç–∞ MEPHI.

---

**–ü–æ–¥–≥–æ—Ç–æ–≤–∏–ª:** AI Agent  
**–î–∞—Ç–∞:** 14 —è–Ω–≤–∞—Ä—è 2026  
**–°—Ç–∞—Ç—É—Å:** ‚úÖ –ì–û–¢–û–í–û –ö –ü–ï–†–ï–•–û–î–£ –ö PHASE 4