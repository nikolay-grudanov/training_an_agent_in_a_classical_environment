# –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç PPO Seed 42 - 500K Timesteps

**–î–∞—Ç–∞:** 5 —Ñ–µ–≤—Ä–∞–ª—è 2026 –≥.
**–°—Ç–∞—Ç—É—Å:** ‚úÖ –£–°–ü–ï–®–ù–û –ó–ê–í–ï–†–®–Å–ù
**Convergence:** –î–ê (>200 reward)

---

## üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã

### –§–∏–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å (500K timesteps):
```
Mean Reward: 225.59 ¬± 22.18
Convergence: YES (>200)
Duration: 190.0s (3.17 –º–∏–Ω—É—Ç—ã)
Speed: 3,025 it/s
```

### –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å (400K timesteps):
```
Mean Reward: 235.24 ¬± 25.52
Convergence: YES (>200)
```

**–õ—É—á—à–∏–π —á–µ–∫–ø–æ–∏–Ω—Ç:** `best_model.zip` (checkpoint_400000.zip)

---

## üéØ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è

| –ü–∞—Ä–∞–º–µ—Ç—Ä | –ó–Ω–∞—á–µ–Ω–∏–µ |
|----------|----------|
| –ê–ª–≥–æ—Ä–∏—Ç–º | PPO |
| Timesteps | 500,000 |
| Seed | 42 |
| Gamma | 0.999 |
| Entropy Coefficient | 0.01 |
| GAE Lambda | 0.98 |
| N Steps | 1024 |
| N Epochs | 4 |
| Batch Size | 64 |
| Learning Rate | 3e-4 |
| Device | CPU |

---

## üìà –ö—Ä–∏–≤–∞—è –æ–±—É—á–µ–Ω–∏—è

| Timesteps | Mean Reward | Std Reward | –°—Ç–∞—Ç—É—Å |
|-----------|-------------|-------------|----------|
| 50K | -442.30 | 119.41 | ‚ùå NO |
| 100K | -79.26 | 28.49 | ‚ùå NO |
| 150K | -109.41 | 29.62 | ‚ùå NO |
| 200K | 28.23 | 69.89 | ‚ùå NO |
| 250K | -12.90 | 79.32 | ‚ùå NO |
| 300K | -36.50 | 22.50 | ‚ùå NO |
| 350K | 143.86 | 117.56 | ‚ùå NO |
| **400K** | **243.45** | **22.85** | **‚úÖ YES** |
| 450K | 205.41 | 23.54 | ‚úÖ YES |
| 500K (—Ñ–∏–Ω–∞–ª) | 238.33 | 20.60 | ‚úÖ YES |

**–í—ã–≤–æ–¥:** –ú–æ–¥–µ–ª—å –¥–æ—Å—Ç–∏–≥–ª–∞ –ø–∏–∫–∞ –Ω–∞ 400K timesteps (243.45), –Ω–∞ 500K –Ω–µ–º–Ω–æ–≥–æ —Å–Ω–∏–∑–∏–ª–∞—Å—å –¥–æ 238.33.

---

## üìÅ –§–∞–π–ª—ã —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞

### –û—Å–Ω–æ–≤–Ω—ã–µ —Ñ–∞–π–ª—ã:
```
ppo_seed42_500K/
‚îú‚îÄ‚îÄ ppo_seed42_500K_model.zip  ‚Üê –§–∏–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å (500K timesteps)
‚îú‚îÄ‚îÄ best_model.zip               ‚Üê –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å (400K timesteps, 243.45 reward)
‚îú‚îÄ‚îÄ config.json                 ‚Üê –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
‚îú‚îÄ‚îÄ metrics.csv                 ‚Üê –ú–µ—Ç—Ä–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è
‚îú‚îÄ‚îÄ eval_log.csv               ‚Üê –õ–æ–≥–∏ –æ—Ü–µ–Ω–∫–∏ (–∫–∞–∂–¥—ã–µ 5K timesteps)
‚îî‚îÄ‚îÄ checkpoints/                ‚Üê –í—Å–µ —á–µ–∫–ø–æ–∏–Ω—Ç—ã
    ‚îú‚îÄ‚îÄ checkpoint_50000.zip
    ‚îú‚îÄ‚îÄ checkpoint_100000.zip
    ‚îú‚îÄ‚îÄ ...
    ‚îî‚îÄ‚îÄ checkpoint_500000.zip
```

### –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é:

1. **–î–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏:**
   ```bash
   # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª—É—á—à–∏–π —á–µ–∫–ø–æ–∏–Ω—Ç
   python -c "from src.training.evaluation import evaluate_agent; result = evaluate_agent('results/experiments/ppo_seed42/ppo_seed42_500K/best_model.zip', n_eval_episodes=20); print(result)"
   ```

2. **–î–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏:**
   ```bash
   # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ñ–∏–Ω–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å
   python -c "from src.training.evaluation import evaluate_agent; result = evaluate_agent('results/experiments/ppo_seed42/ppo_seed42_500K/ppo_seed42_500K_model.zip', n_eval_episodes=20); print(result)"
   ```

---

## üîç –ê–Ω–∞–ª–∏–∑

### –ß—Ç–æ —Ö–æ—Ä–æ—à–æ:
- ‚úÖ –î–æ—Å—Ç–∏–≥–ª–∏ —Ü–µ–ª–∏ >200 reward
- ‚úÖ –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –æ—Ç–ª–∏—á–Ω–∞—è (Std ~20-25)
- ‚úÖ –û–±—É—á–µ–Ω–∏–µ –ø—Ä–æ—à–ª–æ –±—ã—Å—Ç—Ä–æ (3.17 –º–∏–Ω—É—Ç—ã)
- ‚úÖ –£—Ç–∏–ª–∏–∑–∞—Ü–∏—è CPU –ø–æ–ª–Ω–∞—è (32 –ø–æ—Ç–æ–∫–∞)

### –ß—Ç–æ –º–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å:
- ‚ö†Ô∏è –û–±—É—á–µ–Ω–∏–µ –±—ã–ª–æ –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω—ã–º –¥–æ 350K timesteps
- ‚ö†Ô∏è –ú–æ–¥–µ–ª—å –¥–æ—Å—Ç–∏–≥–ª–∞ –ø–∏–∫–∞ –Ω–∞ 400K, –∑–∞—Ç–µ–º –Ω–µ–º–Ω–æ–≥–æ —Å–Ω–∏–∑–∏–ª–∞—Å—å

### –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:
1. ‚ùå **–ù–ï –¥–æ–æ–±—É—á–∞—Ç—å –¥–∞–ª—å—à–µ** (–ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —É–∂–µ –Ω–∞ 400K)
2. ‚úÖ **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å checkpoint_400000.zip** –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω—É—é –º–æ–¥–µ–ª—å
3. ‚úÖ **–ü—Ä–æ–±–æ–≤–∞—Ç—å –¥—Ä—É–≥–∏–µ seeds** –¥–ª—è —É—Å—Ä–µ–¥–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

---

## üìö –°–≤—è–∑–∞–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã

- **[EXPERIMENT_ORGANIZATION.md](../../EXPERIMENT_ORGANIZATION.md)** - –û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
- **[SYSTEM_SPECS.md](../../SYSTEM_SPECS.md)** - –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ —Å–∏—Å—Ç–µ–º—ã
- **[GRID_SEARCH_RESULTS.md](../../GRID_SEARCH_RESULTS.md)** - –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

---

## üí° –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### –û—Ü–µ–Ω–∏—Ç—å –ª—É—á—à—É—é –º–æ–¥–µ–ª—å:
```bash
python -c "
from src.training.evaluation import evaluate_agent
result = evaluate_agent('results/experiments/ppo_seed42/ppo_seed42_500K/best_model.zip', n_eval_episodes=20)
print(f'Mean: {result[\"mean_reward\"]:.2f} ¬± {result[\"std_reward\"]:.2f}')
print(f'Convergence: {\"YES\" if result[\"convergence_achieved\"] else \"NO\"}')
"
```

### –°—Ä–∞–≤–Ω–∏—Ç—å —Å –¥—Ä—É–≥–∏–º–∏ –º–æ–¥–µ–ª—è–º–∏:
```bash
python -c "
from src.training.evaluation import evaluate_agent

models = [
    'results/experiments/ppo_seed42/ppo_seed42_500K/best_model.zip',
    'results/experiments/ppo_seed999/ppo_seed999_model.zip',
]

for model in models:
    result = evaluate_agent(model, n_eval_episodes=10)
    name = model.split('/')[-2]
    print(f'{name}: {result[\"mean_reward\"]:.2f} ¬± {result[\"std_reward\"]:.2f}')
"
```

---

**–°–æ–∑–¥–∞–Ω–æ:** 5 —Ñ–µ–≤—Ä–∞–ª—è 2026 –≥.
