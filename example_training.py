#!/usr/bin/env python3
"""
–ü—Ä–∏–º–µ—Ä –∑–∞–ø—É—Å–∫–∞ –æ–±—É—á–µ–Ω–∏—è PPO –∞–≥–µ–Ω—Ç–∞ –Ω–∞ CartPole-v1.

–≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –±–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã –æ–±—É—á–µ–Ω–∏—è RL –∞–≥–µ–Ω—Ç–æ–≤.
"""

import sys
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å
sys.path.append(str(Path(__file__).parent))

from src.training import Trainer, TrainerConfig
from src.agents import PPOConfig


def main():
    print("üöÄ –ó–∞–ø—É—Å–∫ –ø—Ä–∏–º–µ—Ä–∞ –æ–±—É—á–µ–Ω–∏—è PPO –∞–≥–µ–Ω—Ç–∞ –Ω–∞ CartPole-v1")
    print("=" * 60)

    # –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
    config = TrainerConfig(
        experiment_name="ppo_cartpole_example",
        algorithm="PPO",
        environment_name="CartPole-v1",
        total_timesteps=10000,  # –£–º–µ–Ω—å—à–µ–Ω–æ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø—Ä–∏–º–µ—Ä–∞
        seed=42,
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ—Ü–µ–Ω–∫–∏
        eval_freq=2000,
        n_eval_episodes=5,
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        save_freq=5000,
        
        # –ü—É—Ç–∏
        output_dir="results/example",
        
        # –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
        verbose=1,
        progress_bar=True,
    )

    print(f"üìã –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–æ–∑–¥–∞–Ω–∞:")
    print(f"   ‚Ä¢ –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç: {config.experiment_name}")
    print(f"   ‚Ä¢ –ê–ª–≥–æ—Ä–∏—Ç–º: {config.algorithm}")
    print(f"   ‚Ä¢ –°—Ä–µ–¥–∞: {config.environment_name}")
    print(f"   ‚Ä¢ –®–∞–≥–∏ –æ–±—É—á–µ–Ω–∏—è: {config.total_timesteps:,}")
    print(f"   ‚Ä¢ Seed: {config.seed}")
    print()

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –±–∞–∑–æ–≤–æ–≥–æ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    from src.utils.logging import setup_logging
    setup_logging(log_level="INFO", console_output=True)

    # –°–æ–∑–¥–∞–Ω–∏–µ –∏ –∑–∞–ø—É—Å–∫ —Ç—Ä–µ–Ω–µ—Ä–∞
    print("ü§ñ –°–æ–∑–¥–∞–Ω–∏–µ —Ç—Ä–µ–Ω–µ—Ä–∞...")
    with Trainer(config) as trainer:
        print("üéØ –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è...")
        result = trainer.train()

        if result.success:
            print("\n‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ!")
            print(f"üìä –§–∏–Ω–∞–ª—å–Ω–∞—è –Ω–∞–≥—Ä–∞–¥–∞: {result.final_mean_reward:.2f} ¬± {result.final_std_reward:.2f}")
            print(f"üèÜ –õ—É—á—à–∞—è –Ω–∞–≥—Ä–∞–¥–∞: {result.best_mean_reward:.2f}")
            print(f"‚è±Ô∏è  –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {result.training_time:.1f} —Å–µ–∫")
            print(f"üíæ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {result.model_path}")

            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
            print("\nüîç –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞...")
            eval_result = trainer.evaluate(n_episodes=10, render=False)
            print(f"üìà –°—Ä–µ–¥–Ω—è—è –Ω–∞–≥—Ä–∞–¥–∞: {eval_result['mean_reward']:.2f}")
            print(f"üìè –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ —ç–ø–∏–∑–æ–¥–∞: {eval_result['mean_length']:.1f}")
        else:
            print(f"\n‚ùå –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–∏–ª–æ—Å—å —Å –æ—à–∏–±–∫–æ–π: {result.error_message}")

    print("\nüéâ –ü—Ä–∏–º–µ—Ä –∑–∞–≤–µ—Ä—à–µ–Ω!")


if __name__ == "__main__":
    main()