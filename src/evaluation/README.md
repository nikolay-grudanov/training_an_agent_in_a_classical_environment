# –ú–æ–¥—É–ª—å –æ—Ü–µ–Ω–∫–∏ RL –∞–≥–µ–Ω—Ç–æ–≤

–ú–æ–¥—É–ª—å `src.evaluation` –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–π –æ—Ü–µ–Ω–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–Ω—ã—Ö RL –∞–≥–µ–Ω—Ç–æ–≤.

## üéØ –û—Å–Ω–æ–≤–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏

- **–ö–æ–ª–∏—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∞–≥–µ–Ω—Ç–æ–≤** - —Ä–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
- **–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑** - –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã, —Ç–µ—Å—Ç—ã –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏
- **–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∞–≥–µ–Ω—Ç–æ–≤** - —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –º–æ–¥–µ–ª–µ–π
- **–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–æ–≤** - –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–æ–≤ –≤ —Ç–µ–∫—Å—Ç–æ–≤–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
- **–≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö** - —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ CSV/DataFrame
- **–í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç—å** - –∫–æ–Ω—Ç—Ä–æ–ª—å —Å–ª—É—á–∞–π–Ω–æ—Å—Ç–∏ –¥–ª—è –ø–æ–≤—Ç–æ—Ä—è–µ–º—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

## üìä –ú–µ—Ç—Ä–∏–∫–∏ –æ—Ü–µ–Ω–∫–∏

### –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
- **–ù–∞–≥—Ä–∞–¥—ã**: —Å—Ä–µ–¥–Ω–µ–µ, —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ, –º–∏–Ω–∏–º—É–º, –º–∞–∫—Å–∏–º—É–º
- **–î–ª–∏–Ω–∞ —ç–ø–∏–∑–æ–¥–æ–≤**: —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —à–∞–≥–æ–≤
- **–î–æ–ª—è —É—Å–ø–µ—à–Ω—ã—Ö —ç–ø–∏–∑–æ–¥–æ–≤**: –ø—Ä–æ—Ü–µ–Ω—Ç —ç–ø–∏–∑–æ–¥–æ–≤ –≤—ã—à–µ –ø–æ—Ä–æ–≥–∞

### –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –º–µ—Ç—Ä–∏–∫–∏
- **–î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã** –¥–ª—è —Å—Ä–µ–¥–Ω–µ–π –Ω–∞–≥—Ä–∞–¥—ã
- **t-—Ç–µ—Å—Ç—ã** –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –∞–≥–µ–Ω—Ç–æ–≤
- **–†–∞–∑–º–µ—Ä —ç—Ñ—Ñ–µ–∫—Ç–∞** (Cohen's d) –¥–ª—è –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–π –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏

## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

```python
import gymnasium as gym
from src.evaluation.evaluator import Evaluator
from src.agents.ppo_agent import PPOAgent

# –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ä–µ–¥—ã –∏ –∞–≥–µ–Ω—Ç–∞
env = gym.make("CartPole-v1")
agent = PPOAgent.load("path/to/model.zip", env=env)

# –°–æ–∑–¥–∞–Ω–∏–µ –æ—Ü–µ–Ω—â–∏–∫–∞
evaluator = Evaluator(
    env=env,
    success_threshold=200.0,  # –ü–æ—Ä–æ–≥ —É—Å–ø–µ—Ö–∞ –¥–ª—è CartPole
    confidence_level=0.95,
    random_seed=42,
)

# –û—Ü–µ–Ω–∫–∞ –∞–≥–µ–Ω—Ç–∞
metrics = evaluator.evaluate_agent(
    agent=agent,
    num_episodes=100,
    agent_name="PPO_CartPole",
)

print(f"–°—Ä–µ–¥–Ω—è—è –Ω–∞–≥—Ä–∞–¥–∞: {metrics.mean_reward:.3f}")
print(f"–î–æ–ª—è —É—Å–ø–µ—à–Ω—ã—Ö —ç–ø–∏–∑–æ–¥–æ–≤: {metrics.success_rate:.1%}")
```

## üìã –û—Å–Ω–æ–≤–Ω—ã–µ –∫–ª–∞—Å—Å—ã

### `Evaluator`
–ì–ª–∞–≤–Ω—ã–π –∫–ª–∞—Å—Å –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∞–≥–µ–Ω—Ç–æ–≤.

**–ú–µ—Ç–æ–¥—ã:**
- `evaluate_agent()` - –æ—Ü–µ–Ω–∫–∞ –æ–¥–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞
- `compare_agents()` - —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–≤—É—Ö –∞–≥–µ–Ω—Ç–æ–≤
- `evaluate_multiple_agents()` - –æ—Ü–µ–Ω–∫–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∞–≥–µ–Ω—Ç–æ–≤
- `generate_report()` - –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –æ—Ç—á–µ—Ç–∞
- `export_to_dataframe()` - —ç–∫—Å–ø–æ—Ä—Ç –≤ pandas DataFrame

### `EvaluationMetrics`
Dataclass —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –æ—Ü–µ–Ω–∫–∏ –∞–≥–µ–Ω—Ç–∞.

**–ü–æ–ª—è:**
- `mean_reward`, `std_reward` - —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –Ω–∞–≥—Ä–∞–¥
- `mean_episode_length` - —Å—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ —ç–ø–∏–∑–æ–¥–∞
- `success_rate` - –¥–æ–ª—è —É—Å–ø–µ—à–Ω—ã—Ö —ç–ø–∏–∑–æ–¥–æ–≤
- `reward_ci_lower`, `reward_ci_upper` - –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª
- `episode_rewards`, `episode_lengths` - –¥–µ—Ç–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ

### `ComparisonResult`
–†–µ–∑—É–ª—å—Ç–∞—Ç —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –¥–≤—É—Ö –∞–≥–µ–Ω—Ç–æ–≤.

**–ü–æ–ª—è:**
- `better_agent` - –∏–º—è –ª—É—á—à–µ–≥–æ –∞–≥–µ–Ω—Ç–∞
- `reward_ttest_pvalue` - p-value t-—Ç–µ—Å—Ç–∞ –¥–ª—è –Ω–∞–≥—Ä–∞–¥
- `reward_significant` - —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –∑–Ω–∞—á–∏–º–æ—Å—Ç—å —Ä–∞–∑–ª–∏—á–∏–π
- `reward_effect_size` - —Ä–∞–∑–º–µ—Ä —ç—Ñ—Ñ–µ–∫—Ç–∞ (Cohen's d)

## üîß –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

### Callback –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞

```python
class ProgressCallback:
    def on_episode_start(self, episode: int) -> None:
        if episode % 10 == 0:
            print(f"–≠–ø–∏–∑–æ–¥ {episode}")
    
    def on_episode_end(self, episode: int, reward: float, length: int, success: bool) -> None:
        pass
    
    def on_evaluation_end(self, metrics: EvaluationMetrics) -> None:
        print(f"–û—Ü–µ–Ω–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {metrics.mean_reward:.3f}")

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
callback = ProgressCallback()
metrics = evaluator.evaluate_agent(agent, num_episodes=50, callback=callback)
```

### –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∞–≥–µ–Ω—Ç–æ–≤

```python
# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–≤—É—Ö –∞–≥–µ–Ω—Ç–æ–≤
comparison = evaluator.compare_agents(
    agent1=ppo_agent,
    agent2=a2c_agent,
    num_episodes=100,
    agent1_name="PPO",
    agent2_name="A2C",
)

print(f"–õ—É—á—à–∏–π –∞–≥–µ–Ω—Ç: {comparison.better_agent}")
print(f"–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –∑–Ω–∞—á–∏–º–æ: {comparison.reward_significant}")
print(f"–†–∞–∑–º–µ—Ä —ç—Ñ—Ñ–µ–∫—Ç–∞: {comparison.reward_effect_size:.3f}")
```

### –ü–∞–∫–µ—Ç–Ω–∞—è –æ—Ü–µ–Ω–∫–∞

```python
agents = {
    "PPO": ppo_agent,
    "A2C": a2c_agent,
    "SAC": sac_agent,
}

results = evaluator.evaluate_multiple_agents(agents, num_episodes=50)

# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞
report = evaluator.generate_report(results)
print(report)

# –≠–∫—Å–ø–æ—Ä—Ç –≤ DataFrame
df = evaluator.export_to_dataframe(results)
df.to_csv("agent_comparison.csv")
```

## üìà –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

### –î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã
- **95% –î–ò**: —Å 95% –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é –∏—Å—Ç–∏–Ω–Ω–æ–µ —Å—Ä–µ–¥–Ω–µ–µ –ª–µ–∂–∏—Ç –≤ —ç—Ç–æ–º –∏–Ω—Ç–µ—Ä–≤–∞–ª–µ
- **–£–∑–∫–∏–π –∏–Ω—Ç–µ—Ä–≤–∞–ª**: –≤—ã—Å–æ–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å –æ—Ü–µ–Ω–∫–∏
- **–®–∏—Ä–æ–∫–∏–π –∏–Ω—Ç–µ—Ä–≤–∞–ª**: –≤—ã—Å–æ–∫–∞—è –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç—å, –Ω—É–∂–Ω–æ –±–æ–ª—å—à–µ —ç–ø–∏–∑–æ–¥–æ–≤

### –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –∑–Ω–∞—á–∏–º–æ—Å—Ç—å
- **p < 0.05**: —Ä–∞–∑–ª–∏—á–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –∑–Ω–∞—á–∏–º—ã
- **p ‚â• 0.05**: —Ä–∞–∑–ª–∏—á–∏—è –º–æ–≥—É—Ç –±—ã—Ç—å —Å–ª—É—á–∞–π–Ω—ã–º–∏

### –†–∞–∑–º–µ—Ä —ç—Ñ—Ñ–µ–∫—Ç–∞ (Cohen's d)
- **|d| < 0.2**: –º–∞–ª—ã–π —ç—Ñ—Ñ–µ–∫—Ç
- **0.2 ‚â§ |d| < 0.8**: —Å—Ä–µ–¥–Ω–∏–π —ç—Ñ—Ñ–µ–∫—Ç  
- **|d| ‚â• 0.8**: –±–æ–ª—å—à–æ–π —ç—Ñ—Ñ–µ–∫—Ç

## üéõÔ∏è –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

### –ü–∞—Ä–∞–º–µ—Ç—Ä—ã Evaluator

```python
evaluator = Evaluator(
    env=env,                    # –°—Ä–µ–¥–∞ –¥–ª—è –æ—Ü–µ–Ω–∫–∏
    success_threshold=200.0,    # –ü–æ—Ä–æ–≥ —É—Å–ø–µ—Ö–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    confidence_level=0.95,      # –£—Ä–æ–≤–µ–Ω—å –¥–æ–≤–µ—Ä–∏—è –¥–ª—è –î–ò
    random_seed=42,             # –°–µ–º—è –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
)
```

### –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ—Ü–µ–Ω–∫–∏

```python
metrics = evaluator.evaluate_agent(
    agent=agent,
    num_episodes=100,           # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–∏–∑–æ–¥–æ–≤
    max_steps_per_episode=1000, # –õ–∏–º–∏—Ç —à–∞–≥–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    render=False,               # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å—Ä–µ–¥—ã
    callback=None,              # Callback –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
    agent_name="MyAgent",       # –ò–º—è –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è
    use_cache=True,             # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∫—ç—à–∞
)
```

## üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

–ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤:

```bash
# –í—Å–µ —Ç–µ—Å—Ç—ã –º–æ–¥—É–ª—è
pytest tests/unit/evaluation/ -v

# –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ç–µ—Å—Ç
pytest tests/unit/evaluation/test_evaluator.py::TestEvaluator::test_evaluate_agent_basic -v

# –° –ø–æ–∫—Ä—ã—Ç–∏–µ–º
pytest tests/unit/evaluation/ --cov=src.evaluation --cov-report=html
```

## üìù –ü—Ä–∏–º–µ—Ä—ã

–ü–æ–ª–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
- `examples/evaluation_example.py` - –±–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
- `examples/advanced_evaluation.py` - –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏

## üîç –û—Ç–ª–∞–¥–∫–∞

### –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
–ú–æ–¥—É–ª—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ:

```python
import logging
logging.basicConfig(level=logging.INFO)

# –¢–µ–ø–µ—Ä—å –±—É–¥—É—Ç –≤–∏–¥–Ω—ã —Å–æ–æ–±—â–µ–Ω–∏—è –æ –ø—Ä–æ–≥—Ä–µ—Å—Å–µ –æ—Ü–µ–Ω–∫–∏
metrics = evaluator.evaluate_agent(agent, num_episodes=50)
```

### –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ
–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏ –∫—ç—à–∏—Ä—É—é—Ç—Å—è –ø–æ –∫–ª—é—á—É `{agent_name}_{num_episodes}_{max_steps}`:

```python
# –ü–µ—Ä–≤—ã–π –≤—ã–∑–æ–≤ - –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ
metrics1 = evaluator.evaluate_agent(agent, num_episodes=50, agent_name="test")

# –í—Ç–æ—Ä–æ–π –≤—ã–∑–æ–≤ - –∏–∑ –∫—ç—à–∞
metrics2 = evaluator.evaluate_agent(agent, num_episodes=50, agent_name="test")

# –û—Ç–∫–ª—é—á–µ–Ω–∏–µ –∫—ç—à–∞
metrics3 = evaluator.evaluate_agent(agent, num_episodes=50, use_cache=False)
```

## ü§ù –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è

### –° –¥—Ä—É–≥–∏–º–∏ –º–æ–¥—É–ª—è–º–∏
- `src.agents.*` - –≤—Å–µ —Ç–∏–ø—ã –∞–≥–µ–Ω—Ç–æ–≤ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è
- `src.utils.seeding` - –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
- `src.utils.logging` - —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ

### –° –≤–Ω–µ—à–Ω–∏–º–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º–∏
- **pandas** - —ç–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ DataFrame
- **scipy.stats** - —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Å—Ç—ã
- **gymnasium** - —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å–æ –≤—Å–µ–º–∏ —Å—Ä–µ–¥–∞–º–∏

## üìö API Reference

–ü–æ–ª–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è API –¥–æ—Å—Ç—É–ø–Ω–∞ –≤ docstring'–∞—Ö –∫–ª–∞—Å—Å–æ–≤ –∏ –º–µ—Ç–æ–¥–æ–≤. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `help()` –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø—Ä–∞–≤–∫–∏:

```python
help(Evaluator.evaluate_agent)
help(EvaluationMetrics)
```