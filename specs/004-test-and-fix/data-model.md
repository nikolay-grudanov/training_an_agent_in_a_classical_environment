# Data Model: ML Project Artifacts & Entities

**Feature**: 004-test-and-fix | **Date**: 2026-02-04
**Project Type**: Machine Learning (Reinforcement Learning) | **Phase**: 1 (Design & Contracts)

---

## üìã NOTE: ML Project Architecture

**–≠—Ç–æ ML –ø—Ä–æ–µ–∫—Ç (Reinforcement Learning), NOT traditional web application.**

**–û—Ç–ª–∏—á–∏—è –æ—Ç —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤:**
- ‚ùå **–ù–µ—Ç REST API** - ML –º–æ–¥–µ–ª–∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –Ω–∞–ø—Ä—è–º—É—é —á–µ—Ä–µ–∑ Python API
- ‚ùå **–ù–µ—Ç –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö** - –î–∞–Ω–Ω—ã–µ —Ö—Ä–∞–Ω—è—Ç—Å—è –≤ —Ñ–∞–π–ª–∞—Ö (CSV, JSON, ZIP)
- ‚úÖ **–ï—Å—Ç—å ML –º–æ–¥–µ–ª–∏** - –û–±—É—á–µ–Ω–Ω—ã–µ –∞–≥–µ–Ω—Ç—ã (PPO, A2C, TD3)
- ‚úÖ **–ï—Å—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏** - YAML/JSON –∫–æ–Ω—Ñ–∏–≥–∏ –¥–ª—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
- ‚úÖ **–ï—Å—Ç—å –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã –æ–±—É—á–µ–Ω–∏—è** - –ú–µ—Ç—Ä–∏–∫–∏, —á–µ–∫–ø–æ–∏–Ω—Ç—ã, –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏, –≤–∏–¥–µ–æ

**–ü–æ–ª–Ω—É—é –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é —Å–º. –≤ –ø–∞–ø–∫–µ `/docs/`:
- [PROJECT_CONTEXT.md](../../docs/PROJECT_CONTEXT.md) - –û–±–∑–æ—Ä –ø—Ä–æ–µ–∫—Ç–∞
- [PROJECT_COMPLETION_REPORT.md](../../docs/PROJECT_COMPLETION_REPORT.md) - –§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
- [CPU_vs_GPU_Comparison.md](../../docs/CPU_vs_GPU_Comparison.md) - –°—Ä–∞–≤–Ω–µ–Ω–∏–µ CPU/GPU
- [TROUBLESHOOTING.md](../../docs/TROUBLESHOOTING.md) - –†–µ—à–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º
- [QUICKSTART.md](../../docs/QUICKSTART.md) - –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

---

## –°—É—â–Ω–æ—Å—Ç–∏ ML –ø—Ä–æ–µ–∫—Ç–∞

### 1. Model (–û–±—É—á–µ–Ω–Ω—ã–π –∞–≥–µ–Ω—Ç)

**–û–ø–∏—Å–∞–Ω–∏–µ**: –û–±—É—á–µ–Ω–Ω—ã–π RL –∞–≥–µ–Ω—Ç, —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–π –≤ —Ñ–æ—Ä–º–∞—Ç–µ Stable-Baselines3 (.zip)

**–ü–æ–ª—è**:
```python
{
    "model_name": "ppo_seed42",
    "algorithm": "PPO",
    "environment": "LunarLander-v3",
    "timesteps": 500000,
    "seed": 42,
    "file_path": "results/experiments/ppo_seed42/ppo_seed42_model.zip",
    "file_size": 145KB,
    "device": "cpu",
    "mean_reward": 203.15,
    "std_reward": 53.74
}
```

**–í–∞–ª–∏–¥–∞—Ü–∏—è**:
- –§–∞–π–ª .zip –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤–∞–ª–∏–¥–Ω—ã–º (–º–æ–∂–Ω–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å —á–µ—Ä–µ–∑ PPO.load())
- Config.json –¥–æ–ª–∂–µ–Ω —Å–æ–≤–ø–∞–¥–∞—Ç—å —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –æ–±—É—á–µ–Ω–∏—è
- –°—Ä–µ–¥–Ω—è—è –Ω–∞–≥—Ä–∞–¥–∞ > 200 (—Ü–µ–ª–µ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ)

**–û—Ç–Ω–æ—à–µ–Ω–∏—è**:
- Model ‚Üí Checkpoint (model –∏–º–µ–µ—Ç —á–µ–∫–ø–æ–∏–Ω—Ç—ã)
- Model ‚Üí TrainingMetrics (model –∏–º–µ–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è)
- Model ‚Üí EvaluationMetrics (model –∏–º–µ–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –æ—Ü–µ–Ω–∫–∏)

---

### 2. TrainingMetrics (–ú–µ—Ç—Ä–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è)

**–û–ø–∏—Å–∞–Ω–∏–µ**: CSV —Ñ–∞–π–ª —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –æ–±—É—á–µ–Ω–∏—è –ø–æ –≤—Å–µ–º —ç–ø–∏–∑–æ–¥–∞–º

**–§–∞–π–ª**: `results/experiments/ppo_seed42/metrics.csv`

**–ü–æ–ª—è** (–∫–æ–ª–æ–Ω–∫–∏ CSV):
```csv
timesteps,episode,mean_reward,std_reward,episode_length,policy_loss,value_loss,entropy_loss,learning_rate,ent_coef
0,1,-100.5,50.2,128,0.5,1.2,0.8,0.0003,0.01
1000,10,50.3,30.1,150,0.4,1.0,0.7,0.0003,0.01
...
500000,489,203.15,53.74,180,0.1,0.5,0.3,0.0003,0.01
```

**–¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö**:
- `timesteps`: int (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤ –æ–±—É—á–µ–Ω–∏—è)
- `episode`: int (–Ω–æ–º–µ—Ä —ç–ø–∏–∑–æ–¥–∞)
- `mean_reward`: float (—Å—Ä–µ–¥–Ω—è—è –Ω–∞–≥—Ä–∞–¥–∞)
- `std_reward`: float (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –Ω–∞–≥—Ä–∞–¥—ã)
- `episode_length`: int (–¥–ª–∏–Ω–∞ —ç–ø–∏–∑–æ–¥–∞)
- `policy_loss`, `value_loss`, `entropy_loss`: float (loss —Ñ—É–Ω–∫—Ü–∏–∏)
- `learning_rate`: float (—Ç–µ–∫—É—â–∏–π learning rate)
- `ent_coef`: float (entropy coefficient)

**–í–∞–ª–∏–¥–∞—Ü–∏—è**:
- –§–∞–π–ª –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤–∞–ª–∏–¥–Ω—ã–º CSV (–º–æ–∂–µ—Ç –±—ã—Ç—å –ø—Ä–æ—á–∏—Ç–∞–Ω pandas.read_csv())
- –í—Å–µ —á–∏—Å–ª–æ–≤—ã–µ –ø–æ–ª—è –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —á–∏—Å–ª–∞–º–∏
- mean_reward –≤ –ø–æ—Å–ª–µ–¥–Ω–µ–π —Å—Ç—Ä–æ–∫–µ > 200
- std_reward –≤ –ø–æ—Å–ª–µ–¥–Ω–µ–π —Å—Ç—Ä–æ–∫–µ < 100

**–û—Ç–Ω–æ—à–µ–Ω–∏—è**:
- TrainingMetrics ‚Üí Model (–ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∏—Ç –æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏)

---

### 3. EvaluationMetrics (–ú–µ—Ç—Ä–∏–∫–∏ –æ—Ü–µ–Ω–∫–∏)

**–û–ø–∏—Å–∞–Ω–∏–µ**: CSV —Ñ–∞–π–ª —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö —ç–ø–∏–∑–æ–¥–∞—Ö

**–§–∞–π–ª**: `results/experiments/ppo_seed42/eval_log.csv`

**–ü–æ–ª—è** (–∫–æ–ª–æ–Ω–∫–∏ CSV):
```csv
episode,episode_length,reward,mean_reward,std_reward,min_reward,max_reward
1,178,210.5,203.15,53.74,150.2,280.3
2,182,195.3,203.15,53.74,145.1,270.5
...
10,175,201.8,203.15,53.74,140.5,285.2
```

**–¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö**:
- `episode`: int (–Ω–æ–º–µ—Ä —ç–ø–∏–∑–æ–¥–∞ –æ—Ü–µ–Ω–∫–∏)
- `episode_length`: int (–¥–ª–∏–Ω–∞ —ç–ø–∏–∑–æ–¥–∞)
- `reward`: float (–Ω–∞–≥—Ä–∞–¥–∞ –∑–∞ —ç–ø–∏–∑–æ–¥)
- `mean_reward`, `std_reward`: float (—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –≤—Å–µ–º —ç–ø–∏–∑–æ–¥–∞–º)
- `min_reward`, `max_reward`: float (–º–∏–Ω/–º–∞–∫—Å –Ω–∞–≥—Ä–∞–¥–∞)

**–í–∞–ª–∏–¥–∞—Ü–∏—è**:
- –§–∞–π–ª –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤–∞–ª–∏–¥–Ω—ã–º CSV
- –û–±—ã—á–Ω–æ 10-20 —ç–ø–∏–∑–æ–¥–æ–≤ –æ—Ü–µ–Ω–∫–∏
- mean_reward > 200
- std_reward < 100

**–û—Ç–Ω–æ—à–µ–Ω–∏—è**:
- EvaluationMetrics ‚Üí Model (–ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∏—Ç –æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏)

---

### 4. Checkpoint (–ß–µ–∫–ø–æ–∏–Ω—Ç)

**–û–ø–∏—Å–∞–Ω–∏–µ**: –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è

**–§–∞–π–ª**: `results/experiments/ppo_seed42/checkpoints/rl_model_100000_steps.zip`

**–ü–æ–ª—è**:
```python
{
    "checkpoint_name": "rl_model_100000_steps",
    "timesteps": 100000,
    "file_path": "results/experiments/ppo_seed42/checkpoints/rl_model_100000_steps.zip",
    "file_size": 140KB,
    "mean_reward_at_checkpoint": 150.3
}
```

**–í–∞–ª–∏–¥–∞—Ü–∏—è**:
- –ß–µ–∫–ø–æ–∏–Ω—Ç—ã —Å–æ–∑–¥–∞—é—Ç—Å—è –∫–∞–∂–¥—ã–µ 100K timesteps
- –§–∞–π–ª .zip –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤–∞–ª–∏–¥–Ω—ã–º
- –°—Ä–µ–¥–Ω—è—è –Ω–∞–≥—Ä–∞–¥–∞ —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç—Å—è —Å –∫–∞–∂–¥—ã–º —á–µ–∫–ø–æ–∏–Ω—Ç–æ–º

**–û—Ç–Ω–æ—à–µ–Ω–∏—è**:
- Checkpoint ‚Üí Model (–ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∏—Ç –æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏)

---

### 5. Configuration (–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞)

**–û–ø–∏—Å–∞–Ω–∏–µ**: JSON —Ñ–∞–π–ª —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –æ–±—É—á–µ–Ω–∏—è

**–§–∞–π–ª**: `results/experiments/ppo_seed42/config.json`

**–ü–æ–ª—è**:
```json
{
    "algorithm": "PPO",
    "environment": "LunarLander-v3",
    "timesteps": 500000,
    "seed": 42,
    "gamma": 0.999,
    "ent_coef": 0.01,
    "gae_lambda": 0.98,
    "n_steps": 1024,
    "n_epochs": 4,
    "batch_size": 64,
    "learning_rate": 0.0003,
    "device": "cpu",
    "n_envs": 1,
    "created_at": "2026-02-04T12:00:00Z"
}
```

**–¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö**:
- `algorithm`: string ("PPO", "A2C", "TD3")
- `environment`: string ("LunarLander-v3")
- `timesteps`, `seed`, `n_steps`, `n_epochs`, `batch_size`: int
- `gamma`, `ent_coef`, `gae_lambda`, `learning_rate`: float
- `device`: string ("cpu", "auto", "cuda")
- `created_at`: datetime (ISO 8601)

**–í–∞–ª–∏–¥–∞—Ü–∏—è**:
- –§–∞–π–ª –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤–∞–ª–∏–¥–Ω—ã–º JSON
- –í—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤–∞–ª–∏–¥–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
- –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–æ–ª–∂–Ω—ã —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å RL Zoo best practices (gamma=0.999, ent_coef=0.01)

**–û—Ç–Ω–æ—à–µ–Ω–∏—è**:
- Configuration ‚Üí Model (–æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏)

---

### 6. Visualization (–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è)

**–û–ø–∏—Å–∞–Ω–∏–µ**: –ì—Ä–∞—Ñ–∏–∫–∏ –∏ –≤–∏–¥–µ–æ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –æ–±—É—á–µ–Ω–∏—è

**–§–∞–π–ª—ã**:
- `reward_curve.png` - –ö—Ä–∏–≤–∞—è –æ–±—É—á–µ–Ω–∏—è (–Ω–∞–≥—Ä–∞–¥–∞ vs timesteps)
- `loss_curves.png` - –ö—Ä–∏–≤—ã–µ loss —Ñ—É–Ω–∫—Ü–∏–π
- `episode_length.png` - –î–ª–∏–Ω–∞ —ç–ø–∏–∑–æ–¥–æ–≤ vs timesteps
- `video.mp4` - –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –æ–±—É—á–µ–Ω–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞

**–ü–æ–ª—è**:
```python
{
    "visualization_name": "reward_curve",
    "type": "plot",
    "file_path": "results/experiments/ppo_seed42/reward_curve.png",
    "file_size": 57KB,
    "format": "PNG",
    "created_at": "2026-02-04T12:05:00Z"
}
```

**–¢–∏–ø—ã –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π**:
- `plot`: PNG –≥—Ä–∞—Ñ–∏–∫–∏ (matplotlib)
- `video`: MP4 –≤–∏–¥–µ–æ (gymnasiumÂΩïÂà∂)

**–í–∞–ª–∏–¥–∞—Ü–∏—è**:
- PNG —Ñ–∞–π–ª—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤–∞–ª–∏–¥–Ω—ã–º–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
- MP4 –≤–∏–¥–µ–æ –¥–æ–ª–∂–Ω–æ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—å—Å—è
- –ì—Ä–∞—Ñ–∏–∫–∏ –¥–æ–ª–∂–Ω—ã –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å —Å—Ö–æ–¥–∏–º–æ—Å—Ç—å (reward > 200)

**–û—Ç–Ω–æ—à–µ–Ω–∏—è**:
- Visualization ‚Üí Model (–≤–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ—Ç –æ–±—É—á–µ–Ω–∏–µ –æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏)

---

## –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞ (Storage Layout)

```
results/
‚îú‚îÄ‚îÄ experiments/                 # –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
‚îÇ   ‚îî‚îÄ‚îÄ ppo_seed42/          # –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç PPO —Å seed=42
‚îÇ       ‚îú‚îÄ‚îÄ ppo_seed42_model.zip          # Model
‚îÇ       ‚îú‚îÄ‚îÄ metrics.csv                    # TrainingMetrics
‚îÇ       ‚îú‚îÄ‚îÄ eval_log.csv                   # EvaluationMetrics
‚îÇ       ‚îú‚îÄ‚îÄ config.json                    # Configuration
‚îÇ       ‚îú‚îÄ‚îÄ reward_curve.png                # Visualization (plot)
‚îÇ       ‚îú‚îÄ‚îÄ loss_curves.png               # Visualization (plot)
‚îÇ       ‚îú‚îÄ‚îÄ episode_length.png             # Visualization (plot)
‚îÇ       ‚îú‚îÄ‚îÄ video.mp4                     # Visualization (video)
‚îÇ       ‚îî‚îÄ‚îÄ checkpoints/                  # Checkpoints
‚îÇ           ‚îú‚îÄ‚îÄ rl_model_100000_steps.zip
‚îÇ           ‚îú‚îÄ‚îÄ rl_model_200000_steps.zip
‚îÇ           ‚îú‚îÄ‚îÄ rl_model_300000_steps.zip
‚îÇ           ‚îî‚îÄ‚îÄ rl_model_400000_steps.zip
‚îú‚îÄ‚îÄ comparison/                  # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
‚îÇ   ‚îú‚îÄ‚îÄ cpu_vs_gpu/             # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ CPU vs GPU
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ metrics.csv
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ comparison.png
‚îÇ   ‚îî‚îÄ‚îÄ parameter_tuning/        # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç—é–Ω–∏–Ω–≥–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
‚îÇ       ‚îú‚îÄ‚îÄ lr_3e4/metrics.csv
‚îÇ       ‚îú‚îÄ‚îÄ lr_1e4/metrics.csv
‚îÇ       ‚îî‚îÄ‚îÄ comparison.png
‚îî‚îÄ‚îÄ reports/                    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º—ã–µ –æ—Ç—á–µ—Ç—ã
    ‚îú‚îÄ‚îÄ training_report_20260204.md
    ‚îî‚îÄ‚îÄ performance_report_20260204.md
```

---

## –°—Ö–µ–º–∞ –æ—Ç–Ω–æ—à–µ–Ω–∏–π (Entity Relationship)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ    Model        ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Configuration      ‚îÇ
‚îÇ  (ppo_*.zip)   ‚îÇ         ‚îÇ  (config.json)      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ                            ‚îÇ
        ‚îÇ 1                          ‚îÇ 1
        ‚îÇ                            ‚îÇ
        ‚îÇ                            ‚îÇ
        ‚îÇ                            ‚îÇ
        ‚îÇ 1                          ‚îÇ
        ‚ñº                            ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                 ‚îÇ
‚îÇ  Checkpoint     ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ
‚îÇ (rl_model_*.zip)‚îÇ                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                 ‚îÇ
                                   ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                 ‚îÇ
‚îÇTrainingMetrics  ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ
‚îÇ  (metrics.csv)  ‚îÇ                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                 ‚îÇ
                                   ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                 ‚îÇ
‚îÇEvaluationMetrics‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ
‚îÇ (eval_log.csv)  ‚îÇ                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                 ‚îÇ
                                   ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                 ‚îÇ
‚îÇ  Visualization  ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ
‚îÇ (*.png, *.mp4) ‚îÇ                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                 ‚îÇ
                                   ‚îÇ
                                   ‚îÇ
                                   ‚îÇ
                            (–æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç)
                                   ‚îÇ
                                   ‚îÇ
                                   ‚îÇ
                            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                            ‚îÇ    Seed    ‚îÇ
                            ‚îÇ   (42)     ‚îÇ
                            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Legend**:
- 1: One-to-one relationship
- ‚ñ∂: Reference / points to
- ‚óÄ: Belongs to

---

## –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ –ø—Ä–∞–≤–∏–ª–∞

### Model Validation
```python
def validate_model(model_path: str, config_path: str) -> bool:
    """
    –í–∞–ª–∏–¥–∞—Ü–∏—è –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
    """
    # 1. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    assert os.path.exists(model_path), "Model file not found"

    # 2. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ > 0
    assert os.path.getsize(model_path) > 0, "Model file is empty"

    # 3. –ü–æ–ø—ã—Ç–∞—Ç—å—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å
    model = PPO.load(model_path)
    assert model is not None, "Failed to load model"

    # 4. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    with open(config_path) as f:
        config = json.load(f)
    assert config["mean_reward"] > 200, "Mean reward < 200"

    return True
```

### TrainingMetrics Validation
```python
def validate_metrics(metrics_path: str) -> bool:
    """
    –í–∞–ª–∏–¥–∞—Ü–∏—è –º–µ—Ç—Ä–∏–∫ –æ–±—É—á–µ–Ω–∏—è
    """
    # 1. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å CSV —Ñ–∞–π–ª —á–∏—Ç–∞–µ—Ç—Å—è
    df = pd.read_csv(metrics_path)

    # 2. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –≤—Å–µ –∫–æ–ª–æ–Ω–∫–∏ —Å—É—â–µ—Å—Ç–≤—É—é—Ç
    required_cols = ["timesteps", "episode", "mean_reward", "std_reward"]
    assert all(col in df.columns for col in required_cols), "Missing columns"

    # 3. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω—é—é —Å—Ç—Ä–æ–∫—É
    last_row = df.iloc[-1]
    assert last_row["mean_reward"] > 200, "Final reward < 200"
    assert last_row["std_reward"] < 100, "Final std > 100"

    return True
```

---

## Migration Notes

**–ù–µ—Ç –º–∏–≥—Ä–∞—Ü–∏–π** - –≠—Ç–æ ML –ø—Ä–æ–µ–∫—Ç, –¥–∞–Ω–Ω—ã–µ —Ö—Ä–∞–Ω—è—Ç—Å—è –≤ —Ñ–∞–π–ª–∞—Ö, –Ω–µ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö.

**–ê—Ä—Ç–µ—Ñ–∞–∫—Ç—ã –≤–µ—Ä—Å–∏–æ–Ω–∏—Ä—É—é—Ç—Å—è** —á–µ—Ä–µ–∑ git (–∫–æ–¥) –∏ gitignore (—Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã):
- –ö–æ–¥: –í–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω –≤ Git (src/, tests/, docs/)
- –†–µ–∑—É–ª—å—Ç–∞—Ç—ã: –ù–µ –≤–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω—ã (results/ –≤ .gitignore)
- –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è: –í–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∞ –≤ Git (docs/)

---

## –°—Å—ã–ª–∫–∏ –Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é

**–ü–æ–ª–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –ø—Ä–æ–µ–∫—Ç–∞** (—Å–º. –ø–∞–ø–∫—É `/docs/`):

- üìÑ [PROJECT_CONTEXT.md](../../docs/PROJECT_CONTEXT.md) - –û–±–∑–æ—Ä –ø—Ä–æ–µ–∫—Ç–∞ –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç
- üìÑ [PROJECT_COMPLETION_REPORT.md](../../docs/PROJECT_COMPLETION_REPORT.md) - –§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç –æ –ø—Ä–æ–µ–∫—Ç–µ
- üìÑ [CPU_vs_GPU_Comparison.md](../../docs/CPU_vs_GPU_Comparison.md) - –î–µ—Ç–∞–ª—å–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ CPU –∏ GPU –æ–±—É—á–µ–Ω–∏—è
- üìÑ [TROUBLESHOOTING.md](../../docs/TROUBLESHOOTING.md) - –†–µ—à–µ–Ω–∏–µ —Ç–∏–ø–∏—á–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º
- üìÑ [QUICKSTART.md](../../docs/QUICKSTART.md) - –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç –∏ –æ—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã

**–ü–ª–∞–Ω—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è**:

- üìã [004-test-and-fix-experiments.md](../../004-test-and-fix-experiments.md) - –ü–ª–∞–Ω –∏–∑ 13 —Ñ–∞–∑ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
- üìã [specs/004-test-and-fix/spec.md](./spec.md) - –°–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è —Ñ–∏—á–∏

---

## –ó–∞–∫–ª—é—á–µ–Ω–∏–µ

–≠—Ç–æ—Ç –¥–æ–∫—É–º–µ–Ω—Ç –æ–ø–∏—Å—ã–≤–∞–µ—Ç data model –¥–ª—è ML –ø—Ä–æ–µ–∫—Ç–∞ (Reinforcement Learning), –≥–¥–µ:
- **–ï–¥–∏–Ω–∏—Ü—ã —Å—É—â–Ω–æ—Å—Ç–µ–π**: ML –º–æ–¥–µ–ª–∏, –º–µ—Ç—Ä–∏–∫–∏, –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏, —á–µ–∫–ø–æ–∏–Ω—Ç—ã, –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
- **–•—Ä–∞–Ω–∏–ª–∏—â–µ**: –§–∞–π–ª–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ (CSV, JSON, ZIP, PNG, MP4)
- **–ù–µ—Ç API**: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ Python API (Stable-Baselines3)
- **–ù–µ—Ç –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö**: –î–∞–Ω–Ω—ã–µ –≤ —Ñ–∞–π–ª–∞—Ö, –≤–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ Git

–î–ª—è –ø–æ–ª–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ —Å–º. –ø–∞–ø–∫—É `/docs/`.
