# Интеграционный тест генерации выходных данных

## Описание

Этот интеграционный тест проверяет полный пайплайн генерации выходных данных для User Story 3 (Generate Required Outputs). Тест охватывает все компоненты системы от подготовки данных до создания итоговых отчетов.

## Архитектура теста

### Основные компоненты

1. **MockAgent** - Мок агента для тестирования без реального обучения
2. **MockEnvironment** - Мок среды для быстрого тестирования
3. **TestOutputGeneration** - Основной класс с тестами

### Тестируемые модули

- `src.visualization.performance_plots` - Генерация графиков производительности
- `src.visualization.agent_demo` - Создание демонстрационных видео
- `src.evaluation.quantitative_eval` - Количественная оценка агентов
- `src.reporting.results_formatter` - Форматирование результатов в отчеты

## Структура тестов

### Тест 1: Подготовка данных обучения
- Проверка создания и валидации мок агентов
- Генерация симулированных данных обучения
- Сохранение данных в CSV формате

### Тест 2: Генерация графиков производительности
- Создание кривых обучения (награда, длина эпизодов)
- Сравнительные графики агентов
- Дашборд метрик
- Интерактивные и статические графики

### Тест 3: Создание демонстрационных видео
- Демо лучшего эпизода агента
- Пакетное создание демо для всех агентов
- Быстрое создание демо через удобные функции
- Обработка ошибок создания видео

### Тест 4: Количественная оценка агентов
- Оценка отдельных агентов на 10-20 эпизодах
- Пакетная оценка нескольких агентов
- Сравнение с базовой линией
- Генерация отчетов оценки в разных форматах

### Тест 5: Форматирование результатов в отчеты
- Отчеты по отдельным агентам
- Сравнительные отчеты
- Отчеты по экспериментам
- Сводные отчеты
- Экспорт в CSV и JSON

### Тест 6: Интеграция между модулями
- Проверка совместимости данных между модулями
- Создание комплексных отчетов о производительности
- Интеграция оценки и отчетности

### Тест 7: Обработка ошибок и граничных случаев
- Пустые данные
- Отсутствующие колонки
- Некорректные агенты
- Неподдерживаемые форматы
- Минимальные и константные данные

### Тест 8: Производительность и время выполнения
- Измерение времени генерации графиков
- Измерение времени оценки агентов
- Измерение времени создания отчетов
- Проверка соответствия требованиям производительности

### Тест 9: Полный workflow генерации выходных данных
- Комплексный тест всего пайплайна
- Проверка создания всех типов файлов
- Валидация результатов
- Измерение общей производительности

## Использование

### Запуск всех тестов
```bash
pytest tests/integration/test_output_generation.py -v
```

### Запуск конкретного теста
```bash
pytest tests/integration/test_output_generation.py::TestOutputGeneration::test_performance_plots_generation -v
```

### Запуск без интеграционных тестов (быстрее)
```bash
pytest tests/integration/test_output_generation.py -v -m "not integration"
```

### Запуск только полного workflow
```bash
pytest tests/integration/test_output_generation.py::TestOutputGeneration::test_full_output_generation_workflow -v -s
```

## Выходные файлы

Тест создает следующую структуру файлов:

```
test_output_generation_<timestamp>/
├── training_data/           # Симулированные данные обучения
│   ├── episode_reward.csv
│   ├── episode_reward_a2c.csv
│   └── episode_length.csv
├── plots/                   # Графики производительности
│   ├── static/
│   │   ├── reward_curve.png
│   │   ├── episode_lengths.png
│   │   ├── loss_curves.png
│   │   └── dashboard.png
│   └── interactive/
│       ├── reward_curve.html
│       └── dashboard.html
├── videos/                  # Демонстрационные видео
│   ├── PPO_Excellent/
│   ├── A2C_Good/
│   └── SAC_Poor/
├── evaluation/              # Результаты оценки
│   ├── evaluation_report.txt
│   ├── evaluation_report.json
│   └── evaluation_report.csv
├── reports/                 # Итоговые отчеты
│   ├── ppo_agent_report.html
│   ├── agents_comparison_report.html
│   ├── experiment_report.markdown
│   ├── experiments_summary.html
│   ├── agents_results.csv
│   └── complete_results.json
├── integration/             # Тесты интеграции
│   ├── performance_report/
│   ├── integrated_reports/
│   └── full_pipeline/
├── error_handling/          # Тесты обработки ошибок
├── performance/             # Метрики производительности
│   └── performance_metrics.json
└── full_workflow/           # Полный workflow
    ├── workflow_summary.json
    └── [все вышеперечисленные директории]
```

## Конфигурация

### Фикстуры
- `test_output_dir` - Временная директория для тестов
- `mock_env` - Мок среды LunarLander-v2
- `trained_agents` - Набор мок агентов разного уровня
- `training_data` - Симулированные данные обучения

### Мок объекты
- **MockAgent** - Имитирует поведение обученного агента
- **MockEnvironment** - Имитирует среду Gymnasium

### Параметры производительности
- Время создания графика: < 5 секунд
- Время оценки агента: < 2 секунды  
- Время создания отчета: < 3 секунды

## Особенности реализации

### Моки и патчи
Тест использует обширное мокирование для ускорения выполнения:
- Мокирование записи видео (создание фиктивных файлов)
- Мокирование оценки агентов (симуляция результатов)
- Патчинг функций создания демо

### Детерминированность
- Фиксированные семена для воспроизводимости
- Контролируемая генерация данных
- Предсказуемые результаты тестов

### Обработка ошибок
- Graceful handling неудачных операций
- Проверка граничных случаев
- Валидация входных данных

## Требования

### Зависимости
- pytest
- numpy
- pandas
- matplotlib
- pathlib
- unittest.mock

### Системные требования
- Python 3.10+
- Достаточно места на диске для временных файлов
- Headless режим для matplotlib (автоматически настраивается)

## Отладка

### Сохранение временных файлов
Для отладки можно закомментировать очистку в фикстуре `test_output_dir`:
```python
# if temp_dir.exists():
#     shutil.rmtree(temp_dir)
```

### Детальное логирование
Включите детальное логирование:
```bash
pytest tests/integration/test_output_generation.py -v -s --log-level=DEBUG
```

### Пропуск медленных тестов
```bash
pytest tests/integration/test_output_generation.py -v -m "not slow"
```

## Расширение

### Добавление новых тестов
1. Создайте новый метод в классе `TestOutputGeneration`
2. Используйте существующие фикстуры
3. Следуйте паттерну: подготовка → выполнение → проверка

### Добавление новых мок объектов
1. Наследуйтесь от соответствующих базовых классов
2. Реализуйте необходимые методы
3. Добавьте в фикстуры для переиспользования

### Добавление новых проверок
1. Используйте assert для проверки условий
2. Добавляйте информативные сообщения об ошибках
3. Проверяйте как успешные, так и неуспешные сценарии